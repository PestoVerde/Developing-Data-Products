new.fit <- train(training$classe~., data = trPCA, method = 'rf')
new.fit <- train(trTrain$classe~., data = trPCA, method = 'rf')
confusionMatrix(training$classe,predict(new.fit,testPCA))
confusionMatrix(testPCA$classe,predict(new.fit,testPCA))
confusionMatrix(trPCA$classe,predict(new.fit,testPCA))
names(testPCA)
rm(list = ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
head(vowel.train)
dim(vowel.train)
str(vowel.train)
unique(vowel.train$y)
vowel.train$y <- as.factor(vowel.train$y)
str(vowel.train)
rf.fit <- train(vowel.train$y~., method = 'rf')
library(caret)
rf.fit <- train(vowel.train$y~., method = 'rf')
rf.fit <- train(vowel.train$y~., data= vowel.train, method = 'rf')
gbm.fit <- train(vowel.train$y~., data= vowel.train, method = 'gbm')
?gbm
gbm.model <- train(vowel.train$y~., data= vowel.train, method = 'gbm')
rf.model <- rf.fit
rm(gbm.fit, rf.fit)
rf.confusion.matrix <- confusionMatrix(vowel.test$y,predict(rf.model, vowel.test))
rf.confusion.matrix
gbm.confusion.matrix <- confusionMatrix(vowel.test$y,predict(gbm.model, vowel.test))
gbm.confusion.matrix
?rf
?train
predDF <- data.frame(rf.model, gbm.model, y=vowel.test$y)
pred1 <- predict(rf.model, vowel.test)
pred2 <- predict(gbm.model, vowel.test)
predDF <- data.frame(pred1,pred2,wage=testing$wage)
predDF <- data.frame(pred1,pred2,wage=vowel.test$y)
View(predDF)
predDF <- data.frame(pred1,pred2, y=vowel.test$y)
pred.DF
predDF
combModFit <- train(y ~.,method="gam",data=predDF)
combModFit
combPred <- predict(combModFit,predDF)
combPred
sqrt(sum((combPred-vowel.test$y)^2))
pred3 <- predict(combModFit, vowel.test)
pred3
pred3 <- predict(combModFit, vowel.test$y)
head(pred1)
head(pred2)
head(pred3)
combModFit
pred1
gam.confusion.matrix <- confusionMatrix(vowel.test$y,predict(combModFit, vowel.test))
head(predDF)
predDF$y <- as.factor(predDF$y)
str(predDF)
combModFit <- train(y ~.,method="gam",data=predDF)
gam.confusion.matrix <- confusionMatrix(vowel.test$y,predict(combModFit, vowel.test))
gam.confusion.matrix
head(predDF)
which(predDF$pred1 == predDF$pred2 == predDF$y)
which(predDF$pred1 == predDF$pred2)
a<-which(predDF$pred1 == predDF$pred2)
b<-which(predDF$pred1[b] == predDF$y)
b<-which(predDF$pred1[a] == predDF$y)
b<-which(predDF$pred1[a,] == predDF$y)
b
length(which(predDF$pred1 == predDF$pred2))/length(predDF$y)
a<- predDF$pred1 == predDF$pred2
a
a<- predDF$pred1 == predDF$y
b<- predDF$pred2 == predDF$y
head(a)
head(b)
x <- a*b
x
head(x)
sum(x)/length(predDF$y)
sum(a)
sum(a)/length(predDF$y)
w <-which(predDF$pred1 == predDF$pred2)
length(w))/length(predDF$y)
length(w/length(predDF$y)
length(w)/length(predDF$y)
head(predDF, 115)
head(predDF, 15)
head(w, 15)
w1 <- predDF$pred1[w]
head(w1, 15)
predNUM <- as.numeric(predDF)
predNUM <- as.numeric(as.character(predDF))
head(presNUM, 15)
head(predNUM, 15)
str(predDF)
w2 <- predDF$y[w]
w3 <- which(w1 == w2)
head(w3)
w3 <- w1 == w2
length(w)
length(w3)
predDF
w1 == w2
w3 <- w1 == w2
w3
sum(w3)/length(predDF)
sum(w3)/length(predDF$y)
w
p <- (predDF)[w,]
p
1-sum(w3)/length(predDF$y)
rm(list=ls())
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(adData)
set.seed(3433)
set.seed(62433)
names(adData)
rm(list=ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
gbm.model <- train(vowel.train$y~., data= vowel.train, method = 'gbm')
library(caret)
gbm.model <- train(vowel.train$y~., data= vowel.train, method = 'gbm')
gbm.model <- train(vowel.train$y~., data= vowel.train, method = 'gbm')
rf.model <- train(vowel.train$y~., data= vowel.train, method = 'rf')
pred1 <- predict(rf.model, vowel.test)
pred2 <- predict(gbm.model, vowel.test)
predDF <- data.frame(pred1,pred2,wage=vowel.test$y)
predDF <- data.frame(pred1,pred2, y=vowel.test$y)
w <-which(predDF$pred1 == predDF$pred2)
View(predDF)
rm(list=ls())
library(ElemStatLearn, caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
gbm.model <- train(vowel.train$y~., data= vowel.train, method = 'gbm')
rf.model <- train(vowel.train$y~., data= vowel.train, method = 'rf')
pred1 <- predict(rf.model, vowel.test)
pred2 <- predict(gbm.model, vowel.test)
predDF <- data.frame(pred1,pred2, y=vowel.test$y)
w <-which(predDF$pred1 == predDF$pred2)
p <- (predDF)[w,]
head(p)
head(p, 20)
which(p$pred1 != p$pred2)
which(p$pred1 != p$y)
length(which(p$pred1 != p$y))/length(p$y)
1-length(which(p$pred1 != p$y))/length(p$y)
1-length(which(p$pred1 != p$y))/length(predDF$y)
rm(list=ls())
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
gbm.model <- train(diagnosis ~ ., data= trainning, method = 'gbm')
gbm.model <- train(diagnosis ~ ., data= training, method = 'gbm')
gbm.model <- train(diagnosis ~ ., data= training, method = 'gbm')
rf.model <- train(diagnosis ~ ., data= training, method = 'rf')
lda.model <- train(diagnosis ~ ., data= training, method = 'lda')
rf.cm <- confusionMatrix(testing$diagnosis, predict(rf.model, testing$diagnosis))
rf.cm <- confusionMatrix(testing$diagnosis, predict(rf.model, testing))
gbm.cm <- confusionMatrix(testing$diagnosis, predict(gbm.model, testing))
lda.cm <- confusionMatrix(testing$diagnosis, predict(lda.model, testing))
rf.acc <- rf.cm$overall[1]
gbm.acc <- gbm.cm$overall[1]
lda.acc <- lda.cm$overall[1]
rf.cm
gbm.cm
gbm.model <- train(diagnosis ~ ., data= training, method = 'gbm')
gbm.cm <- confusionMatrix(testing$diagnosis, predict(gbm.model, testing))
gbm.cm
gbm.acc <- gbm.cm$overall[1]
rf.pred <- predict(rf.model, testing)
gbm.pred <- predict(gbm.model, testing)
lda.pred <- predict(lda.model, testing)
predDF <- data.frame(rf.pred, gbm.pred, lda.pred, diag=testing$diagnosis)
head(predDF)
combModFit <- train(diag ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
combPred
confusionMatrix(testing$diagnosis, combPred)
rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(3523)
library(AppliedPredictiveModeling, caret)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
?caret
set.seed(3523)
library(AppliedPredictiveModeling)
library(caret)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
head(concrete)
head(mixtures)
set.seed(233)
?plot.enet
??plot.enet
data(diabetes)
attach(diabetes)
object <- enet(x,y,lambda=1)
par(mfrow=c(2,2))
plot(object)
plot(object,xvar="step")
detach(diabetes)
library(elasticnet)
install.packages(elasticnet)
install.packages("elasticnet")
data(diabetes)
??diabetes
library(data(diabetes))
library(elasticnet)
data(diabetes)
attach(diabetes)
object <- enet(x,y,lambda=1)
par(mfrow=c(2,2))
plot(object)
plot(object,xvar="step")
detach(diabetes)
head(diabetes)
str(diabetes)
View(diabetes)
str(diabetes$x2)
?elasticnet
session()
session.info()
sessionInfo()
?(elasticnet)
?elasticnet
?train
names(concrete)
model <- train(training$CompressiveStrength~., data= training, method = 'lasso')
model
pred <- predict(model, testing)
confusionMatrix(testing$CompressiveStrength, pred)
head(testing)
pred
str(testing)
View(diabetes)
object <- enet(x,y,lambda=1)
?enet
object <- enet(training$CompressiveStrength,training[,-9],lambda=0)
object <- enet(training$CompressiveStrength,training,lambda=0)
object <- enet(training$CompressiveStrength,training[,-9],lambda=0, times=9)
object <- enet(training$CompressiveStrength,training[,-9],lambda=1)
object <- enet(training$CompressiveStrength,training,lambda=1)
object <- enet(training$CompressiveStrength,training,lambda=10)
library(glmnet)
object <- enet(training[,-9],training$CompressiveStrength, lambda=0)
training <- as.numeric(training)
head(training)
str(training)
training$Age <- as.numeric(training$Age)
str(training)
object <- enet(training[,-9],training$CompressiveStrength, lambda=0)
object <- enet(training[,-9],training$CompressiveStrength)
class(training)
x <- training[,-9]
y <- training$CompressiveStrength
head(x)
head(y)
object <- enet(x,y, lambda=0)
is.na(x)
sum(is.na(x))
sum(is.na(y))
deattach(diabetes)
dettach(diabetes)
detach(diabetes)
attach(training)
View(training)
names(training)
object <- enet(Cement,CompressiveStrength)
model  <- cv.glmnet(data, return, standardize=TRUE)
library(glmnet)
install.packages("glmnet")
library(glmnet)
model  <- cv.glmnet(x, y, standardize=TRUE)
mtr <- as.matrix(training)
class(mtr)
str(mtr)
head(mtr)
mtr$CompressiveStrength[1]
mtr[9]
mtr[1]
mtr[2]
x<- as.matrix(x)
y <- as.matrix(y)
model  <- cv.glmnet(x, y, standardize=TRUE)
op <- par(mfrow=c(1, 2))
plot(model$glmnet.fit, "norm",   label=TRUE)
plot(model$glmnet.fit, "lambda", label=TRUE)
par(op)
object <- enet(x,y, lambda=0)
plot(object)
par(mfrow=c(1, 1))
plot(object)
names(training)
object <- enet(x,y, lambda=1)
plot(object)
?enet
object <- enet(x,y, lambda=0)
plot(object)
rm(list=ls())
library(lubridate)
library(caret)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
library(lubridate)
library(caret)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
head(dat)
install.packages("forecast")
library(forecast)
?bat
?bats
View(testing)
View(training)
str(training)
a<-bats(training[,2:3])
tr <- training[,2:3]
head(tr)
a<-bats(tr)
?as.date
tr$date <- as.character(tr$date)
str(tr)
a<-bats(tr)
a<-bats(tstrain)
a
?forecast
?bats
forecast(a)
forecast(a, h=235)
head(testing)
b <- forecast(a, h=235)
head(b)
str(b)
b
class(b)
b$upper
b$upper[,2]
head(testing)
x <- data.frame(test=testing$visitsTumblr, pred = b$upper[,2])
x
head(x)
length(which(x$test < x$pred))/length(x$pred)
rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(caret)
library(e1071)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model <- svm(Species ~ ., data = iris)
head(concrete)
model <- svm(CompressiveStrength ~ ., data = training)
pred <- predict(model, testing)
?confusionMatrix
cm <- confusionMatrix(testing$CompressiveStrength, pred)
pred
View(testing)
cm <- confusionMatrix(testing$CompressiveStrength, pred)
RMSE <- sqrt( mean( (pred.test-testing$CompressiveStrength )^2 , na.rm = T))
RMSE <- sqrt(mean( (pred-testing$CompressiveStrength )^2 , na.rm = T))
RMSE
rm(list=ls())
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), x.s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
library(rChart)
install.packages("rChart")
library(rChart)
install.packages("rCharts")
library(rCharts)
install.packages("devtools")
install_github('rCharts', 'ramnathv')
library(devtools)
install_github('rCharts', 'ramnathv')
?rChart
?RCurl
library(RCurl)
install.packages("RCurl")
install.packages("RCurl")
library(devtools)
install.packages("Rtools")
find_rtools()
find_rtools()
install_github('rCharts', 'ramnathv')
?rCharts
install_github('rCharts', 'ramnathv/rCharts')
install_github('rCharts', 'ramnathv/rCharts/rCharts')
library(devtools)
library(Rtools)
find_rtools()
library(Rtools)
library(RCurl)
install_github('rCharts', 'ramnathv')
?rCharts
library(rCharts)
?dTable
??dTable
library(dplyr)
data("airquality")
d <- data.frame(airquality, stringsAsFactors = FALSE) print(d)
d <- data.frame(airquality, stringsAsFactors = FALSE)
print(d)
dTable(airquality, sPaginationType = "full_numbers")
install.packages("shiny")
library(shiny)
runApp()
runApp()
runApp()
runApp()
runApp()
library(UsingR)
install.packages(UsingR)
install.packages('UsingR')
runApp()
?read.csv
read.table("Dataset.data")
a<-read.table("Dataset.data")
is.na(a)
sum(is.na(a))
names(a)
rm(list-ls())
rm(list=ls())
getwd()
dir()
a <- read.csv("dataset_multipleRegression_categorical.csv")
head(a)
attach(a)
dCONF <- as.numeric(CONF) - 1
plot(CONF, TOTAL, main="Team Salary by Conference", xlab="Conference", ylab="Salary ($1,000s)")
cor(dCONF, TOTAL)
head(a)
linearModel <- lm(TOTAL ~ QB + dCONF, datavar)
linearModel <- lm(TOTAL ~ QB + dCONF, a)
summary(linearModel)
rm(list=ls())
setwd("Developing-Data-Products")
first.data <- read.table("Dataset.data")
names(first.data) <- c("sex", "length", "diameter", "height", "whole_weight",
"shucked_weight", "viscera_weight", "shell_weight",
"rings")
## Since data have been scaled for use with an ANN (by dividing by 200),
## we restore original values.
first.data[,2:8] <- first.data[,2:8]*200
a<-first.data[first.data$sex=="M",]
a<-a[,-1]
head(a)
a$rings<-as.factor(a$rings)
str(a)
library(caret)
set.seed(1234)
inTrain <- createDataPartition(a$rings, p=0.75, list = FALSE)
trTrain <- a[inTrain,]
trTest <- a[-inTrain,]
ctrl <- trainControl(allowParallel = TRUE, method = "cv", number = 5)
new.model<-train(trTrain$rings ~ ., data=trTrain,
trainControl = ctrl, method="rf")
confusionMatrix(trTest$rings, predict(new.model, trTest))
err<-confusionMatrix(trTest$rings, predict(new.model, trTest))
err$overall[1]
a <- 1 - err$overall[1]
names(a) <- "Error"
a
